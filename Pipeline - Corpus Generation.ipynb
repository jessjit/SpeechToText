{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all files\n",
    "import regex as re \n",
    "import glob\n",
    "import unicodedata as ucd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bumblebee.srt', 'Endgame.srt', 'shazam.srt', 'sherlock.srt', 'thor.srt']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#putting movie files in a list\n",
    "list_of_srts = list(glob.glob('*.srt'))\n",
    "list_of_srts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to check if a sentence has hindi\n",
    "def has_hindi(s):\n",
    "    u_codes = [ucd.name(char).split(' ')[0] for char in s]\n",
    "    is_dev = [code=='DEVANAGARI' for code in u_codes]\n",
    "    return any(is_dev)\n",
    "\n",
    "#function to make the sentences by parsing data\n",
    "def make_sentence(line):\n",
    "    sentence = ''\n",
    "    try:\n",
    "        if has_hindi(line):\n",
    "            for i, char in enumerate(line):\n",
    "                if char in allowed:\n",
    "                    if char == ' ':\n",
    "                        sentence += char\n",
    "                    else:\n",
    "                        sentence += ' ' + char\n",
    "                elif ucd.name(char).split(' ')[0] == 'DEVANAGARI':\n",
    "                    sentence += char\n",
    "    except:\n",
    "        pass\n",
    "    return(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9179\n"
     ]
    }
   ],
   "source": [
    "#adding valid sentences to dataframe\n",
    "x = 0\n",
    "data = []\n",
    "total_hindi_lines = []\n",
    "allowed = [',', ' ', '?', '!', 'ред']\n",
    "for i in list_of_srts:\n",
    "    list_lines = []\n",
    "    hindi_sentences = []\n",
    "    try:\n",
    "        with open(i, encoding='utf8') as f:\n",
    "            list_lines += f.read().splitlines()\n",
    "            for line in list_lines:\n",
    "                sentence = make_sentence(line)\n",
    "                if len(sentence) > 0:\n",
    "                    hindi_sentences.append(sentence.strip())\n",
    "                    total_hindi_lines.append(sentence.strip())\n",
    "    except:\n",
    "        print(i)\n",
    "    for sentence in hindi_sentences:\n",
    "        words = sentence.split(' ')\n",
    "        counterr = len(words)\n",
    "        data.append(['Movies',list_of_srts[x].split('.')[0].capitalize(),sentence,counterr])\n",
    "    x = x+1\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a reference dictionary\n",
    "Dictionary = {'Source':'Name of the source from where the sentence is taken', \n",
    "              'Subsource':'Name of the subsource', \n",
    "              'Sentence':'The sentence from the subsource:='+str(len(total_hindi_lines)) ,\n",
    "              'No. of words':'The number of words in the given sentence'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4373\n",
      "62425\n"
     ]
    }
   ],
   "source": [
    "#counting number of unique words\n",
    "corpus = ' '.join(total_hindi_lines)\n",
    "corpus = corpus.split(' ')\n",
    "corpus = list(set(corpus))\n",
    "corpus_set = set(corpus)\n",
    "print(len(corpus))\n",
    "\n",
    "\n",
    "#loading news channel words\n",
    "np_array = np.load('/Users/jessjitsingh/Desktop/Jessjit/Internships/Bobble/unique_words_news.npy')\n",
    "news_list = np_array.flatten()\n",
    "news_set = set(news_list)\n",
    "\n",
    "#concatenating the two unique word sets\n",
    "final_unique_word_set = news_set | corpus_set\n",
    "final_unique_word_list = list(final_unique_word_set)\n",
    "\n",
    "#converting corpus to numpy and adding to dataframe\n",
    "final_numpy_array = np.array(final_unique_word_list)\n",
    "df_unique_words = pd.DataFrame(final_numpy_array, columns = ['Unique Words in Text'])\n",
    "print(len(df_unique_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3462378\n"
     ]
    }
   ],
   "source": [
    "#loading Mobile data CSV File \n",
    "df_mobile_data = pd.read_csv (r'/Users/jessjitsingh/Desktop/Jessjit/Internships/Bobble/hindi_sentences_from_chat.csv')\n",
    "print(len(df_mobile_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191974\n"
     ]
    }
   ],
   "source": [
    "#cleaning,validating and adding mobile data\n",
    "i = 0\n",
    "ser = df_mobile_data['text']\n",
    "frequency = df_mobile_data['frequency']\n",
    "for f in frequency:\n",
    "    if int(f)>30:\n",
    "        sen = ser[i]\n",
    "        integer = frequency[i]\n",
    "        msentence = make_sentence(sen)\n",
    "        if len(msentence)>0:\n",
    "            words = msentence.split(\" \")\n",
    "            words = set(words)\n",
    "            intersect = final_unique_word_set & words\n",
    "            if(intersect==words):\n",
    "                w = ser[i].split(\" \")\n",
    "                v = len(w)\n",
    "                n = int(integer)\n",
    "                l = ['Mobile Data', 'Personal Chat', msentence, v]\n",
    "                data += [l]*n\n",
    "        i = i+1\n",
    "    else:\n",
    "        break\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348435\n"
     ]
    }
   ],
   "source": [
    "#loading news file for new sentences\n",
    "df_news_sentences = pd.read_csv (r'/Users/jessjitsingh/Desktop/Jessjit/Internships/Bobble/hindi_sentences_from_news.csv')\n",
    "print(len(df_news_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540409\n"
     ]
    }
   ],
   "source": [
    "df_final_sentences = pd.DataFrame(data, columns = ['Source', 'Subsource', 'Sentence', 'No. of words'])\n",
    "df_final_sentences = pd.concat([df_final_sentences, df_news_sentences], ignore_index=True)\n",
    "print(len(df_final_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualising length of the words\n",
    "#df_final_sentences.plot.bar(x='Sentence',y='No. of words',rot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_annotations(s,n):\n",
    "    list1 = s.split()\n",
    "    num1 = len(list1)\n",
    "    if num1>2:\n",
    "        x = random.randint(1,num1-2)\n",
    "        if n==1:\n",
    "            list1.insert(x,' <COUGH> ')\n",
    "        if n==2:\n",
    "            list1.insert(x,' <SNEEZE> ')\n",
    "        if n==3:\n",
    "            list1.insert(x,' <CLEAR-THROAT> ')\n",
    "        if n==4:\n",
    "            list1.insert(x,' <PAUSE-'+str(random.randint(1,4))+'-SECONDS> ')\n",
    "        s = ' '.join(list1)\n",
    "    return s\n",
    "def annotate(data_sentence):\n",
    "    x = random.randint(1,101)\n",
    "    if x<30:\n",
    "        y = random.randint(1,101)\n",
    "        if y>50:\n",
    "            data_sentence = add_annotations(data_sentence,4)\n",
    "        else:\n",
    "            z = random.randint(1,101)\n",
    "            if z<33:\n",
    "                data_sentence = add_annotations(data_sentence,1)\n",
    "            elif 33<=z<66:\n",
    "                data_sentence = add_annotations(data_sentence,2)\n",
    "            else:\n",
    "                data_sentence = add_annotations(data_sentence,3)\n",
    "    return(data_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540409\n"
     ]
    }
   ],
   "source": [
    "length = len(df_final_sentences)\n",
    "df_final_sentences['Sentence'] = df_final_sentences['Sentence'].apply(annotate)\n",
    "df_final_sentences = df_final_sentences.drop(['Unnamed: 0'],axis=1)\n",
    "print(len(df_final_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporting all data as Files\n",
    "df_final_sentences.to_csv (r'/Users/jessjitsingh/Desktop/Jessjit/Internships/Bobble/ALL_SENTENCES_AND_SOURCES.csv', index = None, header=True)\n",
    "df_unique_words.to_csv(r'/Users/jessjitsingh/Desktop/Jessjit/Internships/Bobble/ALL_WORDS.csv',index = None, header=True )\n",
    "with open('Dictionary.txt', 'w') as file:\n",
    "    file.write(json.dumps(Dictionary))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540409\n"
     ]
    }
   ],
   "source": [
    "df_only_final_sentences = df_final_sentences.drop(['Source','Subsource','No. of words'], axis=1)\n",
    "print(len(df_only_final_sentences))\n",
    "df_only_final_sentences.to_csv (r'/Users/jessjitsingh/Desktop/Jessjit/Internships/Bobble/ONLY_SENTENCES.csv', index = None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
